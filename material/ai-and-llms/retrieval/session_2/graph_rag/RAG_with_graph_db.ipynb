{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac5a3238",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation with a Graph Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b1090",
   "metadata": {},
   "source": [
    "This notebook shows how to use LLMs in combination with [Neo4j](https://neo4j.com/), a graph database, to perform Retrieval Augmented Generation (RAG).\n",
    "\n",
    "### Why use RAG?\n",
    "\n",
    "If you want to use LLMs to generate answers based on your own content or knowledge base, instead of providing large context when prompting the model, you can fetch the relevant information in a database and use this information to generate a response. \n",
    "\n",
    "This allows you to:\n",
    "- Reduce hallucinations\n",
    "- Provide relevant, up to date information to your users\n",
    "- Leverage your own content/knowledge base\n",
    "\n",
    "### Why use a graph database?\n",
    "\n",
    "If you have data where relationships between data points are important and you might want to leverage that, then it might be worth considering graph databases instead of traditional relational databases.\n",
    "\n",
    "Graph databases are good to address the following:\n",
    "- Navigating deep hierarchies\n",
    "- Finding hidden connections between items\n",
    "- Discovering relationships between items\n",
    "\n",
    "### Use cases \n",
    "\n",
    "Graph databases are particularly relevant for recommendation systems, network relationships or analysing correlation between data points.  \n",
    "\n",
    "Example use cases for RAG with graph databases include:\n",
    "- Recommendation chatbot\n",
    "- AI-augmented CRM \n",
    "- Tool to analyse customer behavior with natural language\n",
    "\n",
    "Depending on your use case, you can assess whether using a graph database makes sense. \n",
    "\n",
    "In this notebook, we will build a **product recommendation chatbot**, with a graph database that contains Amazon products data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9f40c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We will start by installing and importing the relevant libraries.  \n",
    "\n",
    "Make sure you have your OpenAI account set up and you have your OpenAI API key handy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: run to load environment variables from a .env file.\n",
    "# This is not required if you have exported your env variables in another way or if you set it manually\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key env variable manually\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<your_api_key>\"\n",
    "\n",
    "# print(os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8137d9d3",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will use a dataset that was created from a relational database and converted to a json format, creating relationships between entities with the completions API.\n",
    "\n",
    "We will then load this data into the graph db to be able to query it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b7d91",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4824f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a json dataset from a file\n",
    "file_path = 'amazon_product_kg.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    jsonData = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b943dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_json(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b9e35",
   "metadata": {},
   "source": [
    "### Connecting to db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dede1b1",
   "metadata": {},
   "source": [
    "#### Start Neo4j with required plugins\n",
    "The APOC plugin is **essential** for LangChain Neo4jGraph to work properly.\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  --name neo4j-rag \\\n",
    "  -p 7474:7474 \\\n",
    "  -p 7687:7687 \\\n",
    "  -e NEO4J_AUTH=neo4j/your_password_here \\\n",
    "  -e NEO4J_PLUGINS='[\"apoc\", \"graph-data-science\"]' \\\n",
    "  neo4j:5.15\n",
    "```\n",
    "\n",
    "#### Verify the setup\n",
    "- **HTTP interface**: http://localhost:7474 (Neo4j Browser)\n",
    "- **Bolt connection**: bolt://localhost:7687 (for Python connections)\n",
    "\n",
    "#### Default credentials\n",
    "- **Username**: `neo4j`\n",
    "- **Password**: `your_password_here` (change this to something secure)\n",
    "\n",
    "#### Management commands\n",
    "```bash\n",
    "# Stop the container\n",
    "docker stop neo4j-rag\n",
    "# Remove the container\n",
    "docker rm neo4j-rag\n",
    "```\n",
    "\n",
    "#### Explore database\n",
    "If you want to explore the database, you can download Neo4j Desktop (https://neo4j.com/download/) and add your local address as a new connection.\n",
    "\n",
    "![Neo4j Connection](neo4j_add_connection.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eef9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB credentials\n",
    "url = \"bolt://localhost:7687\"\n",
    "username =\"neo4j\"\n",
    "password = \"your_password_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f46b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=url, \n",
    "    username=username, \n",
    "    password=password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0a71c",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8aa0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(text):\n",
    "    text = str(text).replace(\"'\",\"\").replace('\"','').replace('{','').replace('}', '')\n",
    "    return text\n",
    "\n",
    "# Loop through each JSON object and add them to the db\n",
    "i = 1\n",
    "for obj in jsonData:\n",
    "    print(f\"{i}. {obj['product_id']} -{obj['relationship']}-> {obj['entity_value']}\")\n",
    "    i+=1\n",
    "    query = f'''\n",
    "        MERGE (product:Product {{id: {obj['product_id']}}})\n",
    "        ON CREATE SET product.name = \"{sanitize(obj['product'])}\", \n",
    "                       product.title = \"{sanitize(obj['TITLE'])}\", \n",
    "                       product.bullet_points = \"{sanitize(obj['BULLET_POINTS'])}\", \n",
    "                       product.size = {sanitize(obj['PRODUCT_LENGTH'])}\n",
    "\n",
    "        MERGE (entity:{obj['entity_type']} {{value: \"{sanitize(obj['entity_value'])}\"}})\n",
    "\n",
    "        MERGE (product)-[:{obj['relationship']}]->(entity)\n",
    "        '''\n",
    "    graph.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf5b21",
   "metadata": {},
   "source": [
    "## Querying the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac67e7",
   "metadata": {},
   "source": [
    "### Creating vector indexes\n",
    "\n",
    "In order to efficiently search our database for terms closely related to user queries, we need to use embeddings. To do this, we will create vector indexes on each type of property.\n",
    "\n",
    "We will be using the OpenAIEmbeddings Langchain utility. It's important to note that Langchain adds a pre-processing step, so the embeddings will slightly differ from those generated directly with the OpenAI embeddings API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ddf46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embeddings_model = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(model=embeddings_model),\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    index_name='products',\n",
    "    node_label=\"Product\",\n",
    "    text_node_properties=['name', 'title'],\n",
    "    embedding_node_property='embedding',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_entities(entity_type):\n",
    "    vector_index = Neo4jVector.from_existing_graph(\n",
    "        OpenAIEmbeddings(model=embeddings_model),\n",
    "        url=url,\n",
    "        username=username,\n",
    "        password=password,\n",
    "        index_name=entity_type,\n",
    "        node_label=entity_type,\n",
    "        text_node_properties=['value'],\n",
    "        embedding_node_property='embedding',\n",
    "    )\n",
    "    \n",
    "entities_list = df['entity_type'].unique()\n",
    "\n",
    "for t in entities_list:\n",
    "    embed_entities(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf8b5b6",
   "metadata": {},
   "source": [
    "Useful cypher query\n",
    "```\n",
    "SHOW INDEXES;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2134702e",
   "metadata": {},
   "source": [
    "### Querying the database directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf0e374",
   "metadata": {},
   "source": [
    "Using `GraphCypherQAChain`, we can generate queries against the database using Natural Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93272015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(temperature=0), graph=graph, verbose=True, allow_dangerous_requests=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afab3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"\"\"\n",
    "Help me find curtains\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c41346",
   "metadata": {},
   "source": [
    "### Extracting entities from the prompt\n",
    "\n",
    "However, there is little added value here compared to just writing the Cypher queries ourselves, and it is prone to error.\n",
    "\n",
    "Indeed, asking an LLM to generate a Cypher query directly might result in the wrong parameters being used, whether it's the entity type or the relationship type, as is the case above.\n",
    "\n",
    "We will instead use LLMs to decide what to search for, and then generate the corresponding Cypher queries using templates.\n",
    "\n",
    "For this purpose, we will instruct our model to find relevant entities in the user prompt that can be used to query our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0983fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_types = {\n",
    "    \"product\": \"Item detailed type, for example 'high waist pants', 'outdoor plant pot', 'chef kitchen knife'\",\n",
    "    \"category\": \"Item category, for example 'home decoration', 'women clothing', 'office supply'\",\n",
    "    \"characteristic\": \"if present, item characteristics, for example 'waterproof', 'adhesive', 'easy to use'\",\n",
    "    \"measurement\": \"if present, dimensions of the item\", \n",
    "    \"brand\": \"if present, brand of the item\",\n",
    "    \"color\": \"if present, color of the item\",\n",
    "    \"age_group\": \"target age group for the product, one of 'babies', 'children', 'teenagers', 'adults'. If suitable for multiple age groups, pick the oldest (latter in the list).\"\n",
    "}\n",
    "\n",
    "relation_types = {\n",
    "    \"hasCategory\": \"item is of this category\",\n",
    "    \"hasCharacteristic\": \"item has this characteristic\",\n",
    "    \"hasMeasurement\": \"item is of this measurement\",\n",
    "    \"hasBrand\": \"item is of this brand\",\n",
    "    \"hasColor\": \"item is of this color\", \n",
    "    \"isFor\": \"item is for this age_group\"\n",
    " }\n",
    "\n",
    "entity_relationship_match = {\n",
    "    \"category\": \"hasCategory\",\n",
    "    \"characteristic\": \"hasCharacteristic\",\n",
    "    \"measurement\": \"hasMeasurement\", \n",
    "    \"brand\": \"hasBrand\",\n",
    "    \"color\": \"hasColor\",\n",
    "    \"age_group\": \"isFor\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f'''\n",
    "    You are a helpful agent designed to fetch information from a graph database. \n",
    "    \n",
    "    The graph database links products to the following entity types:\n",
    "    {json.dumps(entity_types)}\n",
    "    \n",
    "    Each link has one of the following relationships:\n",
    "    {json.dumps(relation_types)}\n",
    "\n",
    "    Depending on the user prompt, determine if it possible to answer with the graph database.\n",
    "        \n",
    "    The graph database can match products with multiple relationships to several entities.\n",
    "    \n",
    "    Example user input:\n",
    "    \"Which blue clothing items are suitable for adults?\"\n",
    "    \n",
    "    There are three relationships to analyse:\n",
    "    1. The mention of the blue color means we will search for a color similar to \"blue\"\n",
    "    2. The mention of the clothing items means we will search for a category similar to \"clothing\"\n",
    "    3. The mention of adults means we will search for an age_group similar to \"adults\"\n",
    "    \n",
    "    \n",
    "    Return a json object following the following rules:\n",
    "    For each relationship to analyse, add a key value pair with the key being an exact match for one of the entity types provided, and the value being the value relevant to the user query.\n",
    "    \n",
    "    For the example provided, the expected output would be:\n",
    "    {{\n",
    "        \"color\": \"blue\",\n",
    "        \"category\": \"clothing\",\n",
    "        \"age_group\": \"adults\"\n",
    "    }}\n",
    "    \n",
    "    If there are no relevant entities in the user prompt, return an empty json object.\n",
    "'''\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83100e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))\n",
    "\n",
    "# Define the entities to look for\n",
    "def define_query(prompt, model=\"gpt-4o\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        response_format= {\n",
    "            \"type\": \"json_object\"\n",
    "        },\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96bfc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_queries = [\n",
    "    \"Which pink items are suitable for children?\",\n",
    "    \"Help me find gardening gear that is waterproof\",\n",
    "    \"I'm looking for a bench with dimensions 100x50 for my living room\"\n",
    "]\n",
    "\n",
    "for q in example_queries:\n",
    "    print(f\"Q: '{q}'\\n{define_query(q)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3c1ad",
   "metadata": {},
   "source": [
    "### Generating queries\n",
    "\n",
    "Now that we know what to look for, we can generate the corresponding Cypher queries to query our database. \n",
    "\n",
    "However, the entities extracted might not be an exact match with the data we have, so we will use the GDS cosine similarity function to return products that have relationships with entities similar to what the user is asking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(text):\n",
    "    result = client.embeddings.create(model=embeddings_model, input=text)\n",
    "    return result.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248dc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The threshold defines how closely related words should be. Adjust the threshold to return more or less results\n",
    "def create_query(text, threshold=0.6):\n",
    "    query_data = json.loads(text)\n",
    "    # Creating embeddings\n",
    "    embeddings_data = []\n",
    "    for key, val in query_data.items():\n",
    "        if key != 'product':\n",
    "            embeddings_data.append(f\"${key}Embedding AS {key}Embedding\")\n",
    "    query = \"WITH \" + \",\\n\".join(e for e in embeddings_data)\n",
    "    # Matching products to each entity\n",
    "    query += \"\\nMATCH (p:Product)\\nMATCH \"\n",
    "    match_data = []\n",
    "    for key, val in query_data.items():\n",
    "        if key != 'product':\n",
    "            relationship = entity_relationship_match[key]\n",
    "            match_data.append(f\"(p)-[:{relationship}]->({key}Var:{key})\")\n",
    "    query += \",\\n\".join(e for e in match_data)\n",
    "    similarity_data = []\n",
    "    for key, val in query_data.items():\n",
    "        if key != 'product':\n",
    "            similarity_data.append(f\"gds.similarity.cosine({key}Var.embedding, ${key}Embedding) > {threshold}\")\n",
    "    query += \"\\nWHERE \"\n",
    "    query += \" AND \".join(e for e in similarity_data)\n",
    "    query += \"\\nRETURN p\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf704065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_graph(response):\n",
    "    embeddingsParams = {}\n",
    "    query = create_query(response)\n",
    "    query_data = json.loads(response)\n",
    "    for key, val in query_data.items():\n",
    "        embeddingsParams[f\"{key}Embedding\"] = create_embedding(val)\n",
    "    result = graph.query(query, params=embeddingsParams)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_response = '''{\n",
    "    \"category\": \"clothes\"\n",
    "}'''\n",
    "\n",
    "result = query_graph(example_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7564ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Result\n",
    "print(f\"Found {len(result)} matching product(s):\\n\")\n",
    "for r in result:\n",
    "    print(f\"{r['p']['name']} ({r['p']['id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b1c4b5",
   "metadata": {},
   "source": [
    "### Finding similar items \n",
    "\n",
    "We can then leverage the graph db to find similar products based on common characteristics.\n",
    "\n",
    "This is where the use of a graph db really comes into play.\n",
    "\n",
    "For example, we can look for products that are the same category and have another characteristic in common, or find products that have relationships to the same entities. \n",
    "\n",
    "This criteria is arbitrary and completely depends on what is the most relevant in relation to your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the relationships_threshold to return products that have more or less relationships in common\n",
    "def query_similar_items(product_id, relationships_threshold = 3):\n",
    "    \n",
    "    similar_items = []\n",
    "        \n",
    "    # Fetching items in the same category with at least 1 other entity in common\n",
    "    query_category = '''\n",
    "            MATCH (p:Product {id: $product_id})-[:hasCategory]->(c:category)\n",
    "            MATCH (p)-->(entity)\n",
    "            WHERE NOT entity:category\n",
    "            MATCH (n:Product)-[:hasCategory]->(c)\n",
    "            MATCH (n)-->(commonEntity)\n",
    "            WHERE commonEntity = entity AND p.id <> n.id\n",
    "            RETURN DISTINCT n;\n",
    "        '''\n",
    "    \n",
    "\n",
    "    result_category = graph.query(query_category, params={\"product_id\": int(product_id)})\n",
    "    #print(f\"{len(result_category)} similar items of the same category were found.\")\n",
    "          \n",
    "    # Fetching items with at least n (= relationships_threshold) entities in common\n",
    "    query_common_entities = '''\n",
    "        MATCH (p:Product {id: $product_id})-->(entity),\n",
    "            (n:Product)-->(entity)\n",
    "            WHERE p.id <> n.id\n",
    "            WITH n, COUNT(DISTINCT entity) AS commonEntities\n",
    "            WHERE commonEntities >= $threshold\n",
    "            RETURN n;\n",
    "        '''\n",
    "    result_common_entities = graph.query(query_common_entities, params={\"product_id\": int(product_id), \"threshold\": relationships_threshold})\n",
    "    #print(f\"{len(result_common_entities)} items with at least {relationships_threshold} things in common were found.\")\n",
    "\n",
    "    for i in result_category:\n",
    "        similar_items.append({\n",
    "            \"id\": i['n']['id'],\n",
    "            \"name\": i['n']['name']\n",
    "        })\n",
    "            \n",
    "    for i in result_common_entities:\n",
    "        result_id = i['n']['id']\n",
    "        if not any(item['id'] == result_id for item in similar_items):\n",
    "            similar_items.append({\n",
    "                \"id\": result_id,\n",
    "                \"name\": i['n']['name']\n",
    "            })\n",
    "    return similar_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49722c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ids = ['1519827', '2763742']\n",
    "\n",
    "for product_id in product_ids:\n",
    "    print(f\"Similar items for product #{product_id}:\\n\")\n",
    "    result = query_similar_items(product_id)\n",
    "    print(\"\\n\")\n",
    "    for r in result:\n",
    "        print(f\"{r['name']} ({r['id']})\")\n",
    "    print(\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f66e56e",
   "metadata": {},
   "source": [
    "## Final result\n",
    "\n",
    "Now that we have all the pieces working, we will stitch everything together. \n",
    "\n",
    "We can also add a fallback option to do a product name/title similarity search if we can't find relevant entities in the user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(params):\n",
    "    matches = []\n",
    "    # Querying the db\n",
    "    result = query_graph(params)\n",
    "    for r in result:\n",
    "        product_id = r['p']['id']\n",
    "        matches.append({\n",
    "            \"id\": product_id,\n",
    "            \"name\":r['p']['name']\n",
    "        })\n",
    "    return matches    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search(prompt, k=10):\n",
    "    matches = []\n",
    "    embedding = create_embedding(prompt)\n",
    "    query = \"\"\"\n",
    "    CALL db.index.vector.queryNodes('products', $k, $embedding)\n",
    "    YIELD node AS p, score\n",
    "    RETURN p.id AS id, p.name AS name, score\n",
    "    ORDER BY score DESC\n",
    "    \"\"\"\n",
    "    result = graph.query(query, params={'embedding': embedding, 'k': k})\n",
    "    for r in result:\n",
    "        matches.append({\n",
    "            \"id\": r[\"id\"],\n",
    "            \"name\": r[\"name\"],\n",
    "            \"score\": r[\"score\"]\n",
    "        })\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d271b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_similarity = \"I'm looking for nice curtains\"\n",
    "print(similarity_search(prompt_similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3fe036",
   "metadata": {},
   "source": [
    "### Using together with an OpenAI agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "luapzdvj86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, function_tool\n",
    "from typing import List, Dict, Any\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zkm28psl1wb",
   "metadata": {},
   "source": [
    "#### Tool Functions\n",
    "\n",
    "First, we'll create proper tool functions using the `@function_tool` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ul23q2hg21k",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductMatch(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "\n",
    "class SimilarityMatch(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    score: float\n",
    "\n",
    "@function_tool\n",
    "def search_products_by_entities(search_query: str) -> List[ProductMatch]:\n",
    "    \"\"\"\n",
    "    Search for products based on extracted entities (color, category, etc.).\n",
    "    \n",
    "    Args:\n",
    "        search_query: The user's search query to extract entities from\n",
    "    \n",
    "    Returns:\n",
    "        List of matching products with id and name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use existing entity extraction logic\n",
    "        params = define_query(search_query)\n",
    "        \n",
    "        # If no entities found, return empty list\n",
    "        if not params or params.strip() == \"{}\":\n",
    "            return []\n",
    "            \n",
    "        # Query the database using existing logic\n",
    "        result = query_graph(params)\n",
    "        \n",
    "        matches = []\n",
    "        for r in result:\n",
    "            matches.append(ProductMatch(\n",
    "                id=r['p']['id'],\n",
    "                name=r['p']['name']\n",
    "            ))\n",
    "        \n",
    "        return matches\n",
    "    except Exception as e:\n",
    "        print(f\"Error in search_products_by_entities: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "@function_tool  \n",
    "def search_products_by_similarity(search_query: str, max_results: int = 10) -> List[SimilarityMatch]:\n",
    "    \"\"\"\n",
    "    Perform similarity search against product names and titles.\n",
    "    \n",
    "    Args:\n",
    "        search_query: The user's search query\n",
    "        max_results: Maximum number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of similar products with id, name, and similarity score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matches = []\n",
    "        embedding = create_embedding(search_query)\n",
    "        query = \"\"\"\n",
    "        CALL db.index.vector.queryNodes('products', $k, $embedding)\n",
    "        YIELD node AS p, score\n",
    "        RETURN p.id AS id, p.name AS name, score\n",
    "        ORDER BY score DESC\n",
    "        \"\"\"\n",
    "        result = graph.query(query, params={'embedding': embedding, 'k': max_results})\n",
    "        \n",
    "        for r in result:\n",
    "            matches.append(SimilarityMatch(\n",
    "                id=r[\"id\"],\n",
    "                name=r[\"name\"],\n",
    "                score=r[\"score\"]\n",
    "            ))\n",
    "        \n",
    "        return matches\n",
    "    except Exception as e:\n",
    "        print(f\"Error in search_products_by_similarity: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "@function_tool\n",
    "def find_similar_products(product_id: int, relationships_threshold: int = 3) -> List[ProductMatch]:\n",
    "    \"\"\"\n",
    "    Find products similar to a given product based on graph relationships.\n",
    "    \n",
    "    Args:\n",
    "        product_id: ID of the product to find similarities for\n",
    "        relationships_threshold: Minimum number of shared entities for similarity\n",
    "    \n",
    "    Returns:\n",
    "        List of similar products with id and name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        similar_items = query_similar_items(str(product_id), relationships_threshold)\n",
    "        \n",
    "        matches = []\n",
    "        for item in similar_items:\n",
    "            matches.append(ProductMatch(\n",
    "                id=item['id'],\n",
    "                name=item['name']\n",
    "            ))\n",
    "        \n",
    "        return matches\n",
    "    except Exception as e:\n",
    "        print(f\"Error in find_similar_products: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68kf44bc8bm",
   "metadata": {},
   "source": [
    "#### Product Recommendation Agent\n",
    "\n",
    "Now we'll create the agent with clear instructions and tool integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pz2sjjf5qb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_product_recommendation_agent() -> Agent:\n",
    "    \"\"\"\n",
    "    Create a product recommendation agent with graph database tools.\n",
    "    \n",
    "    Returns:\n",
    "        Agent configured with product search and recommendation tools\n",
    "    \"\"\"\n",
    "    \n",
    "    instructions = f\"\"\"\n",
    "    You are a product recommendation agent that helps users find products from a graph database.\n",
    "    \n",
    "    Your workflow:\n",
    "    1. First, use search_products_by_entities to extract entities (color, category, brand, etc.) \n",
    "       from the user's query and find matching products\n",
    "    2. If that returns no results, use search_products_by_similarity to find products based on \n",
    "       semantic similarity to the user's query\n",
    "    3. If you find products, optionally use find_similar_products to suggest additional \n",
    "       related items based on graph relationships\n",
    "    4. Present results clearly with product names and IDs\n",
    "    \n",
    "    Available entity types for searching:\n",
    "    {json.dumps(entity_types, indent=2)}\n",
    "    \n",
    "    Search Strategy:\n",
    "    - Always try entity-based search first as it's more precise\n",
    "    - Fall back to similarity search if no entities are found or no results returned\n",
    "    - Use similar products feature to enhance recommendations\n",
    "    - Present actual product names and IDs from the database results\n",
    "    - If no products are found, suggest the user provide more specific details\n",
    "    \n",
    "    Format your responses clearly:\n",
    "    - List the number of products found\n",
    "    - Show product names with their IDs in parentheses\n",
    "    - If suggesting similar products, clearly separate them from main results\n",
    "    \n",
    "    Be helpful and accurate - only return products that actually exist in the database.\n",
    "    \"\"\"\n",
    "    \n",
    "    recommendation_agent = Agent(\n",
    "        name=\"product_recommendation_agent\",\n",
    "        instructions=instructions,\n",
    "        tools=[\n",
    "            search_products_by_entities,\n",
    "            search_products_by_similarity, \n",
    "            find_similar_products\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return recommendation_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fzmecojp4l",
   "metadata": {},
   "source": [
    "#### Agent Execution\n",
    "\n",
    "Finally, we'll create a wrapper function for easy agent interaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ltlcm9s9bhg",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def recommend_products(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Get product recommendations using the OpenAI agent.\n",
    "    \n",
    "    Args:\n",
    "        user_query: The user's product search query\n",
    "        \n",
    "    Returns:\n",
    "        Agent's response with product recommendations\n",
    "    \"\"\"\n",
    "    agent = create_product_recommendation_agent()\n",
    "    \n",
    "    try:\n",
    "        result = await Runner.run(agent, user_query)\n",
    "        return result.final_output\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error getting product recommendations: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w0erei4xwql",
   "metadata": {},
   "source": [
    "#### Testing the OpenAI Agent\n",
    "\n",
    "Let's test the OpenAI agent with the same queries we used for the Langchain agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ekklccakb6u",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"I'm searching for pink shirts\",\n",
    "    \"Can you help me find toys for my niece, she's 8\",\n",
    "    \"I'm looking for nice curtains\"\n",
    "]\n",
    "\n",
    "print(\"🤖 OpenAI Agent Product Recommendations\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n[{i}/{len(test_queries)}] Query: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        result = await recommend_products(query)\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")\n",
    "    \n",
    "    if i < len(test_queries):\n",
    "        print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ada009",
   "metadata": {},
   "source": [
    "## Tracing\n",
    "The agents are making multiple calls under the hood that's not seen in the code. All this can be \"traced\" in the OpenAI log console: https://platform.openai.com/logs?api=traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d30aeb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### User experience\n",
    "\n",
    "When the primary objective is to extract specific information from our database, Large Language Models (LLMs) can significantly enhance our querying capabilities.\n",
    "\n",
    "However, it's crucial to base much of this process on robust code logic to ensure a foolproof user experience.\n",
    "\n",
    "For crafting a genuinely conversational chatbot, further exploration in prompt engineering is necessary, possibly incorporating few-shot examples. This approach helps mitigate the risk of generating inaccurate or misleading information and ensures more precise responses.\n",
    "\n",
    "Ultimately, the design choice depends on the desired user experience. For instance, if the aim is to create a visual recommendation system, the importance of a conversational interface is less relevant.\n",
    "\n",
    "### Working with a knowledge graph \n",
    "\n",
    "Retrieving content from a knowledge graph adds complexity but can be useful if you want to leverage connections between items. \n",
    "\n",
    "The querying part of this notebook would work on a relational database as well, the knowledge graph comes in handy when we want to couple the results with similar items that the graph is surfacing. \n",
    "\n",
    "Considering the added complexity, make sure using a knowledge graph is the best option for your use case.\n",
    "If it is the case, feel free to refine what this cookbook presents to match your needs and perform even better!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
